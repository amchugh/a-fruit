{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Get all inputs\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Flatten, LeakyReLU, BatchNormalization, Reshape\n",
    "from keras.optimizers import Adam\n",
    "from keras.engine.input_layer import Input\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions to convert from human-readable images\n",
    "# to images the networks can comprehend\n",
    "def preprocess_input(im):\n",
    "    return (im.astype(np.float32) - 127.5)/127.5\n",
    "def postprocess_input(im):\n",
    "    return ((im * 127.5) + 127.5).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class exists as to keep the entire array of\n",
    "# images out of RAM and instead load them in as needed\n",
    "class ImageLoader():\n",
    "    def __init__(self, img_rows, img_cols, channels, files, func):\n",
    "        self.img_rows = img_rows\n",
    "        self.img_cols = img_cols\n",
    "        self.channels = channels\n",
    "        self.files = files\n",
    "        self.c_index = 0\n",
    "        self.max = len(self.files)\n",
    "        self.func = func    # The post-processing function \n",
    "                            # that should be applied to images\n",
    "    \n",
    "    def getNextFiles(self, num):\n",
    "        arr = []\n",
    "        for i in range(num):\n",
    "            arr.append(self.load_image(self.files[self.c_index]))\n",
    "            self.c_index += 1\n",
    "            if self.c_index == self.max:\n",
    "                print(\"Looping data now\")\n",
    "                self.c_index = 0\n",
    "        return self.func(np.array(arr))\n",
    "        \n",
    "    def load_image(self, filename):\n",
    "        img = Image.open(filename)\n",
    "        if self.channels == 1:\n",
    "            img = img.convert('1')\n",
    "        img = img.resize((self.img_rows,self.img_cols))\n",
    "        img = list(img.getdata())\n",
    "        img = np.array(img)\n",
    "        return img.reshape((self.img_rows,self.img_cols,self.channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NFruit3():\n",
    "    def __init__(self, save_loc):\n",
    "        self.img_rows = 28\n",
    "        self.img_cols = 28\n",
    "        self.channels = 3\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.noise_shape = (100,)\n",
    "        self.save_loc = save_loc\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build and compile the generator\n",
    "        self.generator = self.build_generator()\n",
    "        self.generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "        # The generator takes noise as input and generated imgs\n",
    "        z = Input(shape=self.noise_shape)\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The valid takes generated images as input and determines validity\n",
    "        valid = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator) takes\n",
    "        # noise as input => generates images => determines validity\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.summary()\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(256, input_shape=self.noise_shape))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(1024))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n",
    "        model.add(Reshape(self.img_shape))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=self.noise_shape)\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Flatten(input_shape=img_shape))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(256))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=256, save_interval=50):\n",
    "        # Create the image loader and the give it the collection of images\n",
    "        image_locs = glob(\"fruits/fruits-360/Training/*/*.jpg\")\n",
    "        il = ImageLoader(self.img_rows, self.img_cols, self.channels, image_locs, preprocess_input)\n",
    "        \n",
    "        half_batch = int(batch_size / 2)\n",
    "\n",
    "        print(\"Starting the training...\")\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select a random half batch of images\n",
    "            imgs = il.getNextFiles(half_batch)\n",
    "\n",
    "            noise = np.random.normal(0, 1, (half_batch, 100))\n",
    "\n",
    "            # Generate a half batch of new images\n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "            # Train the discriminator\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "\n",
    "            # The generator wants the discriminator to label the generated samples\n",
    "            # as valid (ones)\n",
    "            valid_y = np.array([1] * batch_size)\n",
    "\n",
    "            # Train the generator\n",
    "            g_loss = self.combined.train_on_batch(noise, valid_y)\n",
    "\n",
    "            # If at save interval then save generated image samples\n",
    "            if epoch % save_interval == 0:\n",
    "                print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "                self.save_imgs(epoch)\n",
    "                \n",
    "        self.save_imgs(epochs)\n",
    "\n",
    "    def save_imgs(self, epoch):\n",
    "        r, c = 5, 5\n",
    "        noise = np.random.normal(0, 1, (r * c, 100))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "        # prepare the images for human viewing\n",
    "        gen_imgs = postprocess_input(gen_imgs)\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt, :,:,0])\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(self.save_loc + (\"epoch_%d.png\" % epoch))\n",
    "        plt.close()\n",
    "        \n",
    "    def save_models(self):\n",
    "        self.generator.save_weights('generator.h5')\n",
    "        self.discriminator.save_weights('discriminator.h5')\n",
    "        self.combined.save_weights('combined.h5')\n",
    "        \n",
    "    def load_models(self):\n",
    "        self.generator.load_weights('generator.h5')\n",
    "        self.discriminator.load_weights('discriminator.h5')\n",
    "        self.combined.load_weights('combined.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 2352)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1204736   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 1,336,321\n",
      "Trainable params: 1,336,321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 256)               25856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2352)              2410800   \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 28, 28, 3)         0         \n",
      "=================================================================\n",
      "Total params: 3,100,720\n",
      "Trainable params: 3,097,136\n",
      "Non-trainable params: 3,584\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "model_2 (Model)              (None, 28, 28, 3)         3100720   \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              (None, 1)                 1336321   \n",
      "=================================================================\n",
      "Total params: 4,437,041\n",
      "Trainable params: 3,097,136\n",
      "Non-trainable params: 1,339,905\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the models\n",
    "nfruit = NFruit3(\"generated_images/attempt_3-1/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iD Student\\AppData\\Local\\conda\\conda\\envs\\tensorflow-env\\lib\\site-packages\\keras\\engine\\training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 0.482825, acc.: 62.50%] [G loss: 0.604590]\n",
      "10 [D loss: 0.096655, acc.: 100.00%] [G loss: 1.722087]\n",
      "20 [D loss: 0.063287, acc.: 100.00%] [G loss: 2.473341]\n",
      "30 [D loss: 0.052483, acc.: 100.00%] [G loss: 3.071517]\n",
      "40 [D loss: 0.028706, acc.: 100.00%] [G loss: 3.584747]\n",
      "50 [D loss: 0.026563, acc.: 100.00%] [G loss: 3.741261]\n",
      "60 [D loss: 0.036286, acc.: 100.00%] [G loss: 3.901250]\n",
      "70 [D loss: 0.012244, acc.: 100.00%] [G loss: 4.057680]\n",
      "80 [D loss: 0.014785, acc.: 100.00%] [G loss: 4.654190]\n",
      "90 [D loss: 0.019698, acc.: 100.00%] [G loss: 4.747510]\n",
      "100 [D loss: 0.008649, acc.: 100.00%] [G loss: 4.684300]\n",
      "110 [D loss: 0.056351, acc.: 96.88%] [G loss: 7.631158]\n",
      "120 [D loss: 1.309178, acc.: 25.00%] [G loss: 4.022639]\n",
      "130 [D loss: 0.063912, acc.: 96.88%] [G loss: 4.197199]\n",
      "140 [D loss: 0.260002, acc.: 90.62%] [G loss: 2.897914]\n",
      "150 [D loss: 0.786109, acc.: 65.62%] [G loss: 3.252831]\n",
      "160 [D loss: 0.140843, acc.: 96.88%] [G loss: 4.306798]\n",
      "170 [D loss: 0.103714, acc.: 100.00%] [G loss: 4.366190]\n",
      "180 [D loss: 0.160636, acc.: 96.88%] [G loss: 3.301298]\n",
      "190 [D loss: 0.210678, acc.: 90.62%] [G loss: 4.487103]\n",
      "200 [D loss: 0.036763, acc.: 100.00%] [G loss: 4.529824]\n",
      "210 [D loss: 0.223326, acc.: 84.38%] [G loss: 4.376943]\n",
      "220 [D loss: 0.060143, acc.: 100.00%] [G loss: 3.811682]\n",
      "230 [D loss: 0.198277, acc.: 90.62%] [G loss: 3.731002]\n",
      "240 [D loss: 0.588836, acc.: 78.12%] [G loss: 2.053103]\n",
      "250 [D loss: 0.071591, acc.: 100.00%] [G loss: 4.147525]\n",
      "260 [D loss: 0.982891, acc.: 53.12%] [G loss: 2.137232]\n",
      "270 [D loss: 0.533662, acc.: 68.75%] [G loss: 2.169037]\n",
      "280 [D loss: 0.086947, acc.: 100.00%] [G loss: 4.315742]\n",
      "290 [D loss: 0.243198, acc.: 90.62%] [G loss: 3.171772]\n",
      "300 [D loss: 0.067707, acc.: 100.00%] [G loss: 4.063260]\n",
      "310 [D loss: 0.054853, acc.: 100.00%] [G loss: 4.199467]\n",
      "320 [D loss: 0.058272, acc.: 100.00%] [G loss: 2.933995]\n",
      "330 [D loss: 7.638639, acc.: 50.00%] [G loss: 3.872823]\n",
      "340 [D loss: 0.045490, acc.: 100.00%] [G loss: 3.937617]\n",
      "350 [D loss: 0.070759, acc.: 100.00%] [G loss: 3.292696]\n",
      "360 [D loss: 8.086790, acc.: 50.00%] [G loss: 4.937675]\n",
      "370 [D loss: 8.068280, acc.: 50.00%] [G loss: 4.384852]\n",
      "380 [D loss: 8.082954, acc.: 50.00%] [G loss: 4.654955]\n",
      "390 [D loss: 8.075451, acc.: 50.00%] [G loss: 4.677260]\n",
      "400 [D loss: 8.064332, acc.: 50.00%] [G loss: 5.863441]\n",
      "410 [D loss: 8.065952, acc.: 50.00%] [G loss: 5.485425]\n",
      "420 [D loss: 8.062237, acc.: 50.00%] [G loss: 6.227829]\n",
      "430 [D loss: 8.062228, acc.: 50.00%] [G loss: 5.337368]\n",
      "440 [D loss: 8.062289, acc.: 50.00%] [G loss: 5.677227]\n",
      "450 [D loss: 8.062061, acc.: 50.00%] [G loss: 5.698415]\n",
      "460 [D loss: 8.063301, acc.: 50.00%] [G loss: 5.885318]\n",
      "470 [D loss: 8.061959, acc.: 50.00%] [G loss: 5.827894]\n",
      "480 [D loss: 8.063572, acc.: 50.00%] [G loss: 5.849431]\n",
      "490 [D loss: 8.062435, acc.: 50.00%] [G loss: 5.731705]\n",
      "500 [D loss: 8.061635, acc.: 50.00%] [G loss: 6.236854]\n",
      "510 [D loss: 8.061339, acc.: 50.00%] [G loss: 5.963973]\n",
      "520 [D loss: 8.060774, acc.: 50.00%] [G loss: 5.936852]\n",
      "530 [D loss: 8.062627, acc.: 50.00%] [G loss: 5.903924]\n",
      "540 [D loss: 8.061137, acc.: 50.00%] [G loss: 6.051028]\n",
      "550 [D loss: 8.061049, acc.: 50.00%] [G loss: 5.990202]\n",
      "560 [D loss: 8.061536, acc.: 50.00%] [G loss: 5.688918]\n",
      "570 [D loss: 8.060882, acc.: 50.00%] [G loss: 5.990954]\n",
      "580 [D loss: 8.060534, acc.: 50.00%] [G loss: 5.963321]\n",
      "590 [D loss: 8.061134, acc.: 50.00%] [G loss: 6.174723]\n",
      "600 [D loss: 8.060688, acc.: 50.00%] [G loss: 5.887177]\n",
      "610 [D loss: 8.060722, acc.: 50.00%] [G loss: 6.081900]\n",
      "620 [D loss: 8.060623, acc.: 50.00%] [G loss: 6.157697]\n",
      "630 [D loss: 8.060658, acc.: 50.00%] [G loss: 5.840120]\n",
      "640 [D loss: 8.060488, acc.: 50.00%] [G loss: 6.099395]\n",
      "650 [D loss: 8.061152, acc.: 50.00%] [G loss: 6.063544]\n",
      "660 [D loss: 8.060534, acc.: 50.00%] [G loss: 6.053108]\n",
      "670 [D loss: 8.060557, acc.: 50.00%] [G loss: 6.335828]\n",
      "680 [D loss: 8.061026, acc.: 50.00%] [G loss: 5.929040]\n",
      "690 [D loss: 8.060966, acc.: 50.00%] [G loss: 5.967618]\n",
      "700 [D loss: 8.060419, acc.: 50.00%] [G loss: 5.877922]\n",
      "710 [D loss: 8.060914, acc.: 50.00%] [G loss: 5.959745]\n"
     ]
    }
   ],
   "source": [
    "# Train the networks for 1000 epochs\n",
    "nfruit.train(epochs=1000, batch_size=32, save_interval=10)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Save the current model\n",
    "nfruit.save_models()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Load the current saved models\n",
    "nfruit.load_models()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Save an example image\n",
    "nfruit.save_imgs(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Get all inputs\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Flatten, LeakyReLU, BatchNormalization, Reshape\n",
    "from keras.optimizers import Adam\n",
    "from keras.engine.input_layer import Input\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions to convert from human-readable images\n",
    "# to images the networks can comprehend\n",
    "def preprocess_input(im):\n",
    "    return (im.astype(np.float32) - 127.5)/127.5\n",
    "def postprocess_input(im):\n",
    "    return ((im * 127.5) + 127.5).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class exists as to keep the entire array of\n",
    "# images out of RAM and instead load them in as needed\n",
    "class ImageLoader():\n",
    "    def __init__(self, img_rows, img_cols, channels, files, func):\n",
    "        self.img_rows = img_rows\n",
    "        self.img_cols = img_cols\n",
    "        self.channels = channels\n",
    "        self.files = files\n",
    "        self.c_index = 0\n",
    "        self.max = len(self.files)\n",
    "        self.func = func    # The post-processing function \n",
    "                            # that should be applied to images\n",
    "    \n",
    "    def getNextFiles(self, num):\n",
    "        arr = []\n",
    "        for i in range(num):\n",
    "            arr.append(self.load_image(self.files[self.c_index]))\n",
    "            self.c_index += 1\n",
    "            if self.c_index == self.max:\n",
    "                print(\"Looping data now\")\n",
    "                self.c_index = 0\n",
    "        return self.func(np.array(arr))\n",
    "        \n",
    "    def load_image(self, filename):\n",
    "        img = Image.open(filename)\n",
    "        if self.channels == 1:\n",
    "            img = img.convert('1')\n",
    "        img = img.resize((self.img_rows,self.img_cols))\n",
    "        img = list(img.getdata())\n",
    "        img = np.array(img)\n",
    "        return img.reshape((self.img_rows,self.img_cols,self.channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NFruit3():\n",
    "    def __init__(self, save_loc):\n",
    "        self.img_rows = 64\n",
    "        self.img_cols = 64\n",
    "        self.channels = 3\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.noise_shape = (100,)\n",
    "        self.save_loc = save_loc\n",
    "        self.doSaveTraining = True\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build and compile the generator\n",
    "        self.generator = self.build_generator()\n",
    "        self.generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "        # The generator takes noise as input and generated imgs\n",
    "        z = Input(shape=self.noise_shape)\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The valid takes generated images as input and determines validity\n",
    "        valid = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator) takes\n",
    "        # noise as input => generates images => determines validity\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.summary()\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(256, input_shape=self.noise_shape))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(1024))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(2048))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n",
    "        model.add(Reshape(self.img_shape))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=self.noise_shape)\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Flatten(input_shape=img_shape))\n",
    "        model.add(Dense(1024))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(256))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=256, save_interval=50, start=0):\n",
    "        # Create the image loader and the give it the collection of images\n",
    "        image_locs = glob(\"fruits/fruits-360/Test/*/*.jpg\")\n",
    "        il = ImageLoader(self.img_rows, self.img_cols, self.channels, image_locs, preprocess_input)\n",
    "        \n",
    "        half_batch = int(batch_size / 2)\n",
    "\n",
    "        print(\"Starting the training...\")\n",
    "        \n",
    "        for epoch in range(start, epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select a random half batch of images\n",
    "            imgs = il.getNextFiles(half_batch)\n",
    "\n",
    "            noise = np.random.normal(0, 1, (half_batch, 100))\n",
    "\n",
    "            # Generate a half batch of new images\n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "            # Train the discriminator\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "\n",
    "            # The generator wants the discriminator to label the generated samples\n",
    "            # as valid (ones)\n",
    "            valid_y = np.array([1] * batch_size)\n",
    "\n",
    "            # Train the generator\n",
    "            g_loss = self.combined.train_on_batch(noise, valid_y)\n",
    "\n",
    "            # If at save interval then save generated image samples\n",
    "            if epoch % save_interval == 0:\n",
    "                print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "                self.save_imgs(epoch)\n",
    "                if self.doSaveTraining:\n",
    "                    self.save_training_imgs(epoch, imgs)\n",
    "                \n",
    "        self.save_imgs(epochs)\n",
    "        \n",
    "    def save_training_imgs(self, epoch, training_imgs):\n",
    "        r, c = 4, 4\n",
    "        hf = (r*c)//2\n",
    "        imgs = postprocess_input(training_imgs)\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(imgs[cnt, :,:,:])\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(self.save_loc + (\"epoch_%d_training.png\" % epoch))\n",
    "        plt.close()\n",
    "        \n",
    "    def save_imgs(self, epoch):\n",
    "        r, c = 4, 4\n",
    "        noise = np.random.normal(0, 1, (r * c, 100))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "        # prepare the images for human viewing\n",
    "        gen_imgs = postprocess_input(gen_imgs)\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt, :,:,:])\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(self.save_loc + (\"epoch_%d.png\" % epoch))\n",
    "        plt.close()\n",
    "        \n",
    "    def save_models(self):\n",
    "        self.generator.save_weights('generator.h5')\n",
    "        self.discriminator.save_weights('discriminator.h5')\n",
    "        self.combined.save_weights('combined.h5')\n",
    "        \n",
    "    def load_models(self):\n",
    "        self.generator.load_weights('generator.h5')\n",
    "        self.discriminator.load_weights('discriminator.h5')\n",
    "        self.combined.load_weights('combined.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 12288)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              12583936  \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 13,240,321\n",
      "Trainable params: 13,240,321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 256)               25856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2048)              2099200   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 12288)             25178112  \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 64, 64, 3)         0         \n",
      "=================================================================\n",
      "Total params: 27,975,424\n",
      "Trainable params: 27,967,744\n",
      "Non-trainable params: 7,680\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "model_2 (Model)              (None, 64, 64, 3)         27975424  \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              (None, 1)                 13240321  \n",
      "=================================================================\n",
      "Total params: 41,215,745\n",
      "Trainable params: 27,967,744\n",
      "Non-trainable params: 13,248,001\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the models\n",
    "nfruit = NFruit3(\"generated_images/attempt_3-11/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iD Student\\AppData\\Local\\conda\\conda\\envs\\tensorflow-env\\lib\\site-packages\\keras\\engine\\training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 0.771962, acc.: 7.03%] [G loss: 0.634349]\n",
      "Looping data now\n",
      "50 [D loss: 0.499506, acc.: 81.93%] [G loss: 5.265211]\n",
      "Looping data now\n",
      "100 [D loss: 0.559352, acc.: 65.82%] [G loss: 2.021865]\n",
      "Looping data now\n",
      "150 [D loss: 0.328662, acc.: 78.71%] [G loss: 1.470869]\n",
      "Looping data now\n",
      "Looping data now\n",
      "200 [D loss: 0.384305, acc.: 73.44%] [G loss: 0.963032]\n",
      "Looping data now\n",
      "250 [D loss: 0.396781, acc.: 74.80%] [G loss: 0.949578]\n",
      "Looping data now\n",
      "300 [D loss: 0.442519, acc.: 55.18%] [G loss: 0.747975]\n",
      "Looping data now\n",
      "Looping data now\n",
      "350 [D loss: 0.381939, acc.: 76.86%] [G loss: 0.867527]\n",
      "Looping data now\n",
      "400 [D loss: 1.018436, acc.: 35.84%] [G loss: 0.734381]\n",
      "Looping data now\n",
      "450 [D loss: 0.432208, acc.: 80.47%] [G loss: 0.946367]\n",
      "Looping data now\n",
      "Looping data now\n",
      "500 [D loss: 0.747735, acc.: 46.09%] [G loss: 0.737277]\n",
      "Looping data now\n",
      "550 [D loss: 0.560114, acc.: 69.14%] [G loss: 0.876225]\n",
      "Looping data now\n",
      "600 [D loss: 0.626781, acc.: 66.50%] [G loss: 0.806359]\n",
      "Looping data now\n",
      "Looping data now\n",
      "650 [D loss: 0.697907, acc.: 61.72%] [G loss: 0.836195]\n",
      "Looping data now\n",
      "700 [D loss: 0.829932, acc.: 37.79%] [G loss: 0.859544]\n",
      "Looping data now\n",
      "750 [D loss: 0.779703, acc.: 38.48%] [G loss: 0.829971]\n",
      "Looping data now\n",
      "800 [D loss: 0.867808, acc.: 29.79%] [G loss: 0.885489]\n",
      "Looping data now\n",
      "Looping data now\n",
      "850 [D loss: 0.937353, acc.: 10.94%] [G loss: 0.796474]\n",
      "Looping data now\n",
      "900 [D loss: 0.780563, acc.: 41.41%] [G loss: 1.032262]\n",
      "Looping data now\n",
      "950 [D loss: 0.631468, acc.: 67.38%] [G loss: 1.058593]\n",
      "Looping data now\n",
      "Looping data now\n",
      "1000 [D loss: 0.836579, acc.: 50.98%] [G loss: 1.011938]\n",
      "Looping data now\n",
      "1050 [D loss: 0.718978, acc.: 49.80%] [G loss: 0.838679]\n",
      "Looping data now\n",
      "1100 [D loss: 0.700426, acc.: 52.93%] [G loss: 0.810156]\n",
      "Looping data now\n",
      "Looping data now\n",
      "1150 [D loss: 0.732090, acc.: 42.77%] [G loss: 1.041820]\n",
      "Looping data now\n",
      "1200 [D loss: 0.512694, acc.: 80.18%] [G loss: 1.237287]\n",
      "Looping data now\n",
      "1250 [D loss: 0.712872, acc.: 37.99%] [G loss: 0.978004]\n",
      "Looping data now\n",
      "Looping data now\n",
      "1300 [D loss: 0.625308, acc.: 69.04%] [G loss: 1.256918]\n",
      "Looping data now\n",
      "1350 [D loss: 0.535517, acc.: 72.75%] [G loss: 1.238306]\n",
      "Looping data now\n",
      "1400 [D loss: 0.602086, acc.: 69.04%] [G loss: 1.159794]\n",
      "Looping data now\n",
      "Looping data now\n",
      "1450 [D loss: 0.997998, acc.: 44.24%] [G loss: 1.306786]\n",
      "Looping data now\n",
      "1500 [D loss: 0.724846, acc.: 51.56%] [G loss: 1.010713]\n",
      "Looping data now\n",
      "1550 [D loss: 0.635939, acc.: 51.17%] [G loss: 1.161488]\n",
      "Looping data now\n",
      "1600 [D loss: 0.481512, acc.: 81.93%] [G loss: 1.313255]\n",
      "Looping data now\n",
      "Looping data now\n",
      "1650 [D loss: 0.763275, acc.: 55.66%] [G loss: 1.034132]\n",
      "Looping data now\n",
      "1700 [D loss: 0.952703, acc.: 20.31%] [G loss: 0.971289]\n",
      "Looping data now\n",
      "1750 [D loss: 0.587531, acc.: 69.04%] [G loss: 1.087180]\n",
      "Looping data now\n",
      "Looping data now\n",
      "1800 [D loss: 0.581035, acc.: 64.84%] [G loss: 1.553059]\n",
      "Looping data now\n",
      "1850 [D loss: 0.601771, acc.: 64.65%] [G loss: 1.902611]\n",
      "Looping data now\n",
      "1900 [D loss: 0.813916, acc.: 40.72%] [G loss: 1.065126]\n",
      "Looping data now\n",
      "Looping data now\n",
      "1950 [D loss: 0.698650, acc.: 64.55%] [G loss: 1.265778]\n",
      "Looping data now\n",
      "2000 [D loss: 0.750913, acc.: 53.03%] [G loss: 1.129921]\n",
      "Looping data now\n",
      "2050 [D loss: 0.904755, acc.: 59.77%] [G loss: 1.113637]\n",
      "Looping data now\n",
      "Looping data now\n",
      "2100 [D loss: 0.681295, acc.: 68.16%] [G loss: 1.272142]\n",
      "Looping data now\n",
      "2150 [D loss: 0.601531, acc.: 61.82%] [G loss: 1.300744]\n",
      "Looping data now\n",
      "2200 [D loss: 0.794446, acc.: 42.77%] [G loss: 1.002871]\n",
      "Looping data now\n",
      "2250 [D loss: 0.155000, acc.: 96.48%] [G loss: 2.183676]\n",
      "Looping data now\n",
      "Looping data now\n",
      "2300 [D loss: 0.694723, acc.: 65.43%] [G loss: 1.336453]\n",
      "Looping data now\n",
      "2350 [D loss: 0.696831, acc.: 53.22%] [G loss: 1.150849]\n",
      "Looping data now\n",
      "2400 [D loss: 0.384658, acc.: 88.67%] [G loss: 1.551153]\n",
      "Looping data now\n",
      "Looping data now\n",
      "2450 [D loss: 0.652950, acc.: 75.00%] [G loss: 1.199288]\n",
      "Looping data now\n",
      "2500 [D loss: 1.072556, acc.: 47.56%] [G loss: 1.143596]\n",
      "Looping data now\n",
      "2550 [D loss: 0.535905, acc.: 80.66%] [G loss: 1.343558]\n",
      "Looping data now\n",
      "Looping data now\n",
      "2600 [D loss: 0.899367, acc.: 50.20%] [G loss: 0.999670]\n",
      "Looping data now\n",
      "2650 [D loss: 0.851979, acc.: 51.46%] [G loss: 1.329504]\n",
      "Looping data now\n",
      "2700 [D loss: 0.545558, acc.: 78.03%] [G loss: 1.408049]\n",
      "Looping data now\n",
      "Looping data now\n",
      "2750 [D loss: 0.546337, acc.: 74.32%] [G loss: 2.107386]\n",
      "Looping data now\n",
      "2800 [D loss: 0.493911, acc.: 75.59%] [G loss: 1.709595]\n",
      "Looping data now\n",
      "2850 [D loss: 0.607482, acc.: 59.77%] [G loss: 1.131474]\n",
      "Looping data now\n",
      "2900 [D loss: 0.434093, acc.: 82.52%] [G loss: 2.234804]\n",
      "Looping data now\n",
      "Looping data now\n",
      "2950 [D loss: 0.388830, acc.: 82.52%] [G loss: 1.651684]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-98c8212aab43>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Train the networks for 1000 epochs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnfruit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1024\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_interval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-910319126371>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, epochs, batch_size, save_interval, start)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[1;31m# Train the generator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m             \u001b[0mg_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcombined\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m             \u001b[1;31m# If at save interval then save generated image samples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow-env\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow-env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow-env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow-env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the networks for 1000 epochs\n",
    "nfruit.train(epochs=10000, batch_size=1024, save_interval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the current model\n",
    "nfruit.save_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the current saved models\n",
    "nfruit.load_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save an example image\n",
    "nfruit.save_imgs(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
